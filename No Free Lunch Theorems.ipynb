{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# No free lunch theorems for supervised learning\n",
    "   **Elvis Sikora** \n",
    "   \n",
    "   elvis.sikora@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Contents:**\n",
    "1. Informal discussion about theory and induction\n",
    "2. Shwartz-David's NFLT + rudiments of PAC-Learning\n",
    "3. Wolpert's NFLT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Why should we even care? What is this all about?\n",
    "**tl;dr:** _there's no universally superior learner, but this might not be super relevant in practice_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Statistical Learning Theory (SLT)\n",
    "SLT is about \n",
    "_fundamental_ rather than _practical_ questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### The job of SLT is not to:\n",
    "* provide tricks to accelerate training a neural net\n",
    "* help us achieve SotA in any specific dataset or learning task\n",
    "* make the results of learning algorithms more interpretable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### The kind of questions SLT helps us address\n",
    "* what is learning?\n",
    "* is it even possible to learn from finite datasets?\n",
    "* how (computationally) hard is learning?\n",
    "* what fundamental tradeoffs are involved in learning?\n",
    "* is there a universally (across all conceivable learning tasks) superior learner?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These questions are philosophical, there might be no _one correct answer_ to them. But SLT provides us with useful ways to reason about them.\n",
    "\n",
    "We'll discuss two theorems that allow us to give a negative answer to the last question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Problem of induction\n",
    "\n",
    "In machine learning terms: can we learn from finite data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### A thought experiment\n",
    "\n",
    "We are tasked with training an ML model to answer the question: will the sun rise 1/jan next year?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Each night, we get out of bed and go take notes on our window:\n",
    "1. on the first day, it was cold, and _the sun did rise_\n",
    "2. on the second day, it was cold again, and _the sun did rise_\n",
    "3. on the third day, it was warm, and _the sun did rise_\n",
    "4. on the fourth day, it was cloudy, but we could nevertheless see that _the sun did rise_\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We collect data for m = 365 days from 1/jan to 31/dec this year.\n",
    "For all 365 examples in our _training set_, the sun did rise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Can we be **sure** about what will happen on 1/jan next year?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The depressing answer: no\n",
    "\n",
    "There is no _logic_ reason to say the sun will rise the next day.\n",
    "\n",
    "Anything could happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### The way out\n",
    "\n",
    "We can fix this issue by introducing an _inductive bias_.\n",
    "That is, we just assume the world works in a specified way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Two different inductive biases\n",
    "\n",
    "Here are two examples of inductive biases we could embed in our learner:\n",
    "1. always predict the majority class - in this case, we predict _the sun will rise_\n",
    "2. always predict the minority class - in this case, we predict _the sun will not rise_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Two different worlds\n",
    "\n",
    "Suppose either one of the following is true:\n",
    "1. the sun always rises \n",
    "2. the sun always rises this year, and then it will never rise again\n",
    "\n",
    "Learners using the two proposed biases will have different performance in this learning task, depending on which world they live in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Which one is the better learner?\n",
    "\n",
    "* the most accurate answer is: the one most adept for its own environment\n",
    "* the practical answer is: the one who says the sun will rise\n",
    "\n",
    "NFLTs formalize these intuitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Two (sets of) NFLTs\n",
    "\n",
    "We'll discuss 2 sets of NFLTs:\n",
    "  + Wolpert's: introduced in a paper in 1996\n",
    "  + Shalev-Shwartz & Ben-David's (Shwartz-David, for short): available at their 2014 textbook\n",
    "* Wolpert's are the most commonly cited ones\n",
    "* Shwartz-David's might be easier to intepret though\n",
    "\n",
    "We'll provide formal statements of both - but not proofs :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Shwart-David's NFLT\n",
    "_as well as a simplified definition of PAC-Learnability_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAC-Learning\n",
    "\n",
    "+ \"PAC\" stands for probably approximately correct\n",
    "+ Leslie Valiant introduced this in 1983\n",
    "+ it was an important part of why he won a Turing Award in 2010"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A (simple) learning problem\n",
    "\n",
    "#### The setting\n",
    "\n",
    "* domain $ X \\in \\mathbb R^p $\n",
    "* output: $Y$\n",
    "* there's an unknown underlying distribution: $P(X, Y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Our task\n",
    "\n",
    "* we are given $m$ training cases, sampled i.i.d. (not always realistic)\n",
    "* we must come up with a classifier $h : X \\rightarrow Y$\n",
    "* we want to minimize the loss function $L$ on _unseen data_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Minimizing the loss\n",
    "\n",
    "* we can _always_ achieve 0 error on the training set\n",
    "* we know the problem with that: we'll likely _overfit_\n",
    "* that is, our classifier will not generalize to unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### How do we solve this problem?\n",
    "\n",
    "* in PAC-learning, we restrict our search space\n",
    "* we do not consider _every possible classifier_\n",
    "* we only allow classifiers from a (predetermined) _hypothesis class_\n",
    "* for example, we could restrict ourselves to work with _linear models_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### hypothesis class == inductive bias\n",
    "\n",
    "If we choose to only consider linear models,\n",
    "it's as if we were saying:\n",
    "\n",
    "    I believe the underlying distribution is well approximated by a linear classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The NFLTs are essentially answering:\n",
    "\n",
    "    You do not know that distribution, anything you assume could in principle be wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Empirical Risk Minimization\n",
    "* our strategy for learning is to minimize training error (ERM)\n",
    "* since we are only considering some possible classifiers, we may not achieve 0 training error\n",
    "\n",
    "**Aside**: _it is common to split the dataset into training, cv and test sets. This doesn't change anything fundamentally in the present discussion. We still only have a finite dataset that might not represent well the true underlying distribution. The decision to split it is internal to the learning procedure._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Is the training error a good approximation for the true error? As it turns out, it depends on the hypothesis class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice:\n",
    "* we do not care about having THE best classifier\n",
    "* any classifier is fine as long as it is not _too much_ worse than the best one\n",
    "\n",
    "In other words, we want to be close to the best classifier in our hypothesis class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### PAC-learnability\n",
    "\n",
    "Let's name the two classifiers we are concerned with:\n",
    "* $h_S$ is the classifier that has lowest training error\n",
    "* $h_{opt}$ is the classifier that has lowest true error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Definition** (_PAC-learning_): We say a hypothesis class is _PAC-learnable_ if for all $\\epsilon$ and $\\delta$, there is a sample size $m$ above which the following holds:\n",
    "\n",
    "$$ P \\big( (\\text{true error of } h_S) - (\\text{true error of } h_{opt} ) \\le \\epsilon \\big) \\ge 1 - \\delta $$\n",
    "\n",
    "$\\epsilon$ and $\\delta$ are real numbers between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### _Probably Approximately Correct_\n",
    "If our hypothesis class is PAC-learnable, we can safely use the strategy of choosing the classifier with lowest training error:\n",
    "* we'll be _approximately correct_: $\\big( (\\text{true error of } h_S) - (\\text{true error of } h_{opt} ) \\le \\epsilon \\big)$\n",
    "* but we cannot **be sure** we will be approximately correct\n",
    "* we can always get a REALLY BAD training set\n",
    "* what we do know is that we will be _probably_ approximately correct: with probability is $1 - \\delta$\n",
    "* if we want to be more correct with higher probability, the required sample size will grow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Learning a PAC-learnable hypothesis class is really convenient: we can happily pick the classifier which achieves lowest training error.\n",
    "\n",
    "We might be interested now in asking things like:\n",
    "1. what kinds of hypothesis classes are PAC-learnable? For example, is the set of all linear functions for a regression problem PAC-learnable?\n",
    "2. how big should the sample size be so we can, for example, be 99.9% sure we'll be worse off by at most 1E-10 from the best classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These are very important questions. As it turns out, SLT offers answers for both.  \n",
    "\n",
    "The theory of VC-dimension and the fundamental theorem of PAC-Learning provide an answer to the first. \n",
    "And there are formulas to answer the second. \n",
    "\n",
    "Unfortunately, we must move on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### So, is machine learning solved?\n",
    "#### Does it all boil down to finding a PAC-learnable hypothesis class?\n",
    "**tl;dr:** _no._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We may get very close to the best classifier in our class, but it might still suck.\n",
    "\n",
    "If we apply logistic regression to classify images on ImageNet, the model will likely be bad.\n",
    "Even if it's almost the best possible logistic regression classifier for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### What gives?\n",
    "\n",
    "A restrictive hypothesis class (e.g., logistic regression):\n",
    "* is usually easy to _learn_ (get to the best possible model for that class)\n",
    "* usually sucks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is the bias-complexity tradeoff. NFLT, in some sense, is a technical way of saying:\n",
    "\n",
    "    We cannot get rid of the bias. Well, at least if we consider the set of all conceivable problems.\n",
    "    \n",
    "Which, again, is the same as saying we must _assume_ our hypothesis class is good for our particular problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Shwartz-David's theorem\n",
    "\n",
    "#### The setting\n",
    "* binary classification (domain X, labels Y = {0, 1})\n",
    "* our training set cannot cover more than half of the domain\n",
    "  - this is a technicality for _really big_ domains (such as the set of all float32 32x32 images)\n",
    "  - intuition: the half of the domain we _do not_ see could _in principle_ be anything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem** (_SD-NFL_): for any learning algorithm we apply and for any fixed training set size we can find a distribution $P(X,Y)$ such that:\n",
    "\n",
    "+ with probability $\\ge$ 1/7 we'll get a training set for which the classifier outputted by the algorithm will have true error $\\ge$ 1/8\n",
    "+ there's a classifier that achieves 0 true error on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Wolpert's NFLT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wolpert & Macleary's theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wolpert, 1996\n",
    "    It cannot be emphasized enough that no claim is being made in this first paper that all algorithms are equivalent in practice, in the real world. In particular, no claim is being made that one should not use cross-validation in the real world. (I have done so myself many times in the past and intend to do so again in the future.) The sole concern of this   paper is what can(not) be formally inferred about the utility of various learning algorithms if one makes no assumptions concerning targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4. Further reading & Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The following is an excelent introduction to machine learning from the point of view of SLT:\n",
    "+ Shalev-Shwartz, Ben-David (2004). _Understanding Machine Learning: From Theory to Algorithms_\n",
    "\n",
    "It's also available as a PDF at the [author's website](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf).\n",
    "\n",
    "<img align=\"left\" src=\"book.jpg\" alt=\"Drawing\" style=\"width: 170px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Originally, Wolpert's NFLTs for learning algorithms were introduced in:\n",
    "+ Wolpert (1996). _The Lack of A Priori Distinctions Between Learning Algorithms and The Existence of A Priori Distinctions Between Learning Algorithms_\n",
    "\n",
    "He published many subsequent works discussing the theorems, such as:\n",
    "+ Wolpert (2012). _What the No Free Lunch Theorems Really Mean; How to Improve Search Algorithms_\n",
    "\n",
    "An introduction to a simplified version of them can be found in:\n",
    "+ Wolpert, (2001). _The Supervised Learning No-Free-Lunch Theorems_\n",
    "\n",
    "Here is a list of websites I consulted:\n",
    "+ https://en.wikipedia.org/wiki/David_Hume#Induction_and_causation\n",
    "+ https://en.wikipedia.org/wiki/Problem_of_induction\n",
    "+ https://mashimo.wordpress.com/2013/03/12/bertrand-russells-inductivist-turkey/\n",
    "+ https://peekaboo-vision.blogspot.com/2019/07/dont-cite-no-free-lunch-theorem.html\n",
    "+ https://amturing.acm.org/award_winners/valiant_2612174.cfm\n",
    "+ http://www.no-free-lunch.org/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
